<HTML><body><h3><p>Automatically assigned DDC number: <FONT COLOR="#cc6600"></FONT></p><p>Manually assigned DDC number: <FONT COLOR="#008000">006312</FONT></p></h3><p><FONT size="+1">Number of references: </FONT>0</p><p><FONT size="+1">Title: </FONT>A Maximum Entropy Approach For Optimal Statistical Classification</p><p><FONT size="+1">Author: </FONT>
      
      
   </p><p><FONT size="+1">Author: </FONT>
      
      
   </p><p><FONT size="+1">Author: </FONT>
      
      
   </p><p><FONT size="+1">Author: </FONT>
      
      
   </p><p><FONT size="+1">Subject: </FONT>David Miller,Ajit Rao,Kenneth Rose,Allen Gersho A Maximum Entropy Approach For Optimal Statistical Classification</p><p><FONT size="+1">Description: </FONT>A global optimization technique is introduced for statistical
classifier design to minimize the probability of classification error.
The method, which is based on ideas from information theory and
analogies to statistical physics, is inherently probabilistic. During
the design phase, data are assigned to classes in probability, with
the probability distributions chosen to maximize entropy subject
to a constraint on the expected classification error. This entropy
maximization problem is seen to be equivalent to a free energy
minimization, motivating a deterministic annealing approach to
minimize the misclassification cost. Our method is applicable to
a variety of classifier structures, including nearest prototype, radial
basis function, and multilayer perceptron-based classifiers.
On standard benchmark examples, the method applied to nearest
prototype classifier design achieves performance improvements
over both the learning vector quantizer, as well as over multilayer
perceptron classi...</p><p><FONT size="+1">Contributor: </FONT>The Pennsylvania State University CiteSeer Archives</p><p><FONT size="+1">Publisher: </FONT>unknown</p><p><FONT size="+1">Date: </FONT>1995-12-10</p><p><FONT size="+1">Pubyear: </FONT>unknown</p><p><FONT size="+1">Format: </FONT>ps</p><p><FONT size="+1">Identifier: </FONT>http://citeseer.ist.psu.edu/140606.html</p><p><FONT size="+1">Source: </FONT>http://scl.ece.ucsb.edu/current/ajit/papers/nnsp95.ps</p><p><FONT size="+1">Language: </FONT>en</p><p><FONT size="+1">Rights: </FONT>unrestricted</p><img src=15_140606.jpeg alt="Graph" /><FONT size="-1"><p>&lt;?xml&nbsp;&nbsp;&nbsp;version="1.0"&nbsp;&nbsp;&nbsp;encoding="UTF-8"?></p><p>&lt;references_metadata></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;rec&nbsp;&nbsp;&nbsp;ID="SELF"&nbsp;&nbsp;&nbsp;Type="SELF"&nbsp;&nbsp;&nbsp;CiteSeer_Book="SELF"&nbsp;&nbsp;&nbsp;CiteSeer_Volume="SELF"&nbsp;&nbsp;&nbsp;Title="A&nbsp;&nbsp;&nbsp;Maximum&nbsp;&nbsp;&nbsp;Entropy&nbsp;&nbsp;&nbsp;Approach&nbsp;&nbsp;&nbsp;For&nbsp;&nbsp;&nbsp;Optimal&nbsp;&nbsp;&nbsp;Statistical&nbsp;&nbsp;&nbsp;Classification"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;identifier&nbsp;&nbsp;&nbsp;Org="ISBN:0780327403"&nbsp;&nbsp;&nbsp;Paper_ID="SELF"&nbsp;&nbsp;&nbsp;Extracted="0780327403"&nbsp;&nbsp;&nbsp;/></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;identifier&nbsp;&nbsp;&nbsp;Org="ISBN:0780399781"&nbsp;&nbsp;&nbsp;Paper_ID="SELF"&nbsp;&nbsp;&nbsp;Extracted="0780399781"&nbsp;&nbsp;&nbsp;/></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/rec></p><p>&lt;/references_metadata></p><p></p><p></body></HTML>